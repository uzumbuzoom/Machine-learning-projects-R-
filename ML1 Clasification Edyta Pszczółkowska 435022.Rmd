---
title: "ML1 Classification - Travel Insurance Prediction"
author: "Edyta Pszczółkowska"
date: "2 08 2021"
output: html_document
---


The presented project is a classification model based on a dataset taken from kaggle: 

https://www.kaggle.com/tejashvi14/travel-insurance-prediction-data

I will try to predict whether a given customer may potentially buy a additional travel insurance. Such a model is a great example how machine learning algorithms and modern statistical packages may support business.

After brief variables review and their transformations I will implement 3 different algorithms: logistic regression, k-nearest neighbors and SVM using 2 different kernel functions - polynomial and radial (gaussian).

Afterwards I will summarize the results obtained on the test sample.

###Loading data and necessary packages:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

setwd("D:\\Edyta pliki\\DS\\II semestr\\ML1")
data <- read.csv("TravelInsurancePrediction.csv")

library(kernlab)
library(dplyr)
library(readr)
library(ggplot2)
library(caret)
library(AER)
library(tibble)
library(purrr)
library(corrplot)
library(DescTools)
library(lmtest) 
library(nnet)
library(caret)
library(verification)
library(janitor) 

library(bestNormalize)
library(Information)

```


###Variables review and their transformation

Let's check the structure of the dataset:
```{r}
glimpse(data)
```

Whereas almost all variable names are rather self- explanatory, let's take a look at "Employment type":

```{r}
table(data$Employment.Type)
```
```{r}
colnames(data)

```

Let's recode this variable and all other binary variables to 0/1 notation and make them factors:

```{r}
data$Employment.Type <-  as.factor(ifelse(data$Employment.Type == "Private Sector/Self Employed", 0 , 1))
data$GraduateOrNot <- as.factor(ifelse(data$GraduateOrNot == "No", 0 , 1))
data$FrequentFlyer <- as.factor(ifelse(data$FrequentFlyer == "No", 0 , 1))
data$EverTravelledAbroad <- as.factor(ifelse(data$EverTravelledAbroad == "No", 0 , 1))
data$ChronicDiseases <- as.factor(data$ChronicDiseases)






summary(data)

```




Let's count missings in every column:

```{r}
colSums(is.na(data)) 
```
No NAs in this dataset, great.


Let's see the distribution of "age" variable - log and normal and after boxcox transormation....
```{r}
ggplot(data,
       aes(x = (data$Age))) +
  geom_histogram(fill = "blue",
                 bins = 50) +
  theme_bw()

ggplot(data,
       aes(x = log(data$Age))) +
  geom_histogram(fill = "blue",
                 bins = 50) +
  theme_bw()


age_bocox <- boxcox(data$Age)
data_age_boxcox <- age_bocox$x.t
hist(data_age_boxcox)

```
"Let's see the distribution of "AnnualIncome" variable - log and normal and after boxcox transormation....


```{r}
ggplot(data,
       aes(x = (data$AnnualIncome))) +
  geom_histogram(fill = "blue",
                 bins = 50) +
  theme_bw()


ggplot(data,
       aes(x = log(data$AnnualIncome+1))) +
  geom_histogram(fill = "blue",
                 bins = 50) +
  theme_bw()


income_bocox <- boxcox(data$AnnualIncome)
data_income_boxcox <- income_bocox$x.t
hist(data_income_boxcox)

```

Neither logaritmic nor boxcox transformation gives as a symmetric outcome so I will try to bin those variables using WOE and IV:


```{r}
# # Caution!!! 
# # df = pure data frame required as input
# # y = - dependent variable -  should be binary and integer
# #       its name cannot include a dot
# # x = continuous variable (with at least 5 different values)
# install.packages("smbinning")
# library(smbinning)
# AnnualIncome_binned <-
#   smbinning(df = data.frame(data), # data
#             y = "TravelInsurance", # dependent - NUMERIC !!!!
#             x = "Age", # continuous variable to be binned
#             p = 0.05) # percentage of obs per bin (between 0 and 0.5)
# 
# # lets see the results
# 
# AnnualIncome_binned$ivtable
```



```{r}
hist(data$FamilyMembers)
```





Let's  check the correlations 
Firstly for numeric variables...:

```{r}
cor(data[,c("Age", "AnnualIncome", "FamilyMembers")],
      use = "pairwise.complete.obs")


```

We don't see any significant collinearity between numerical variables.

Let's see the relationship between the dependent variable and all binary variables:

```{r}

DescTools::CramerV(data$EmploymentType,
                   data$TravelInsurance)
DescTools::CramerV(data$GraduateOrNot,
                   data$TravelInsurance)
DescTools::CramerV(data$ChronicDiseases,
                   data$TravelInsurance)
DescTools::CramerV(data$FrequentFlyer,
                   data$TravelInsurance)
DescTools::CramerV(data$EverTravelledAbroad,
                   data$TravelInsurance)

```
The strongest relationships with the dependent variables are for "EverTravelledAbroad" and "FrequentFlyer" (in this order, all relationships are positive, quite predictable).


Let us check the IV of all predictors:
```{r}
data$TravelInsurance <- as.numeric(data$TravelInsurance)



data_IV <-
  create_infotables(data %>%  
                      dplyr::select(-X),
                    # dependent variable
                    y = "TravelInsurance",
                    bins = 20) 


data_IV_values <- as.data.frame(data_IV$Summary)

print(data_IV_values)
```






No need for further transformations, the dataset is ready for modelling.
Lets divide the data into a learning and testing sample in proportions 30/70% and check the distribution of the target variable in both samples :

```{r}
options(contrasts = c("contr.treatment",  
                      "contr.treatment")) 


data$TravelInsurance <- ifelse(data$TravelInsurance == 1, "Yes", "No")
data$TravelInsurance <- as.factor(data$TravelInsurance)


set.seed(12345)
insurance_which_train <- createDataPartition(data$TravelInsurance, 
                                          p = 0.7, 
                                          list = FALSE) 



insurance_train <- data[insurance_which_train,]
insurance_test <- data[-insurance_which_train,]



table(insurance_train$TravelInsurance)
table(insurance_test$TravelInsurance)

```





###Models

##Logistic regression


For all the models I will use the "train" function from the caret package. I will implement repeated cross validation method with 5 folds and 3 repeats.

Let's play a game...

```{r}

fiveStats <- function(...) c(twoClassSummary(...), 
                             defaultSummary(...))

ctrl_cv5 <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         # and use it in trControl
                         summaryFunction = fiveStats)

model_logistic <- 
  train(TravelInsurance ~ ., 
        data = insurance_train %>% 
          dplyr::select(-X),
        method = "glm",
        family = "binomial",
        trControl = ctrl_cv5)


summary(model_logistic)
model_logistic

```

 
We may see the variables "Employment type", "Graduate or not" and "Chronic diseases" are not significant. For the last two of them it was also proved using IV function.
As the p-values standing next to their coefficients are so high, I will exclude those variables from further analysis and re-estimate the logistic regression model:

```{r}
ctrl_cv5 <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         # and use it in trControl
                         summaryFunction = fiveStats)
model_logistic2 <- 
  train(TravelInsurance ~ ., 
        data = insurance_train %>% 
          dplyr::select(-X, - GraduateOrNot, -ChronicDiseases, -Employment.Type ),
        method = "glm",
        family = "binomial",
        trControl = ctrl_cv5)


summary(model_logistic2)
model_logistic2
```
Slightly better accuracy.

##K-nearest neighbours 

For this part it is crucial to estimate the parameter k. For smaller samples it is advised to take as this value a square root of number of observations. For now, let's  plot the accuracy for  k from 1 to 40 and use method "range" to scale the data:


```{r}
different_k <- data.frame(k = seq(1, 40, 2))


ctrl_cv5 <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         # and use it in trControl
                         summaryFunction = fiveStats)


model_knn <- 
  train(TravelInsurance ~ ., 
        data = insurance_train %>% 
          dplyr::select(-X, - GraduateOrNot, -ChronicDiseases, -Employment.Type ),
        method = "knn",
        preProcess = c("range"),
        trControl = ctrl_cv5,
        tuneGrid = different_k)



model_knn



plot(model_knn)


```


The highest accuracy was obtained for k=19. From k ~ 30 the accuracy is decreasing, so there is no need to check the model for the square root of number of observations (k~~ 44)


###SVM - polynomial


Let's check which value of parameters are optimal:

```{r}
svm_parametersPoly <- expand.grid(C = c(0.001,  1),
                                  degree = 1:5, 
                                  scale = 1)

svm_parametersPoly


ctrl_cv5 <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         # and use it in trControl
                         summaryFunction = fiveStats)

model_SVM_poly <- train(TravelInsurance ~ ., 
        data = insurance_train %>% 
          dplyr::select(-X, - GraduateOrNot, -ChronicDiseases, -Employment.Type),
        method = "svmPoly",
        tuneGrid = svm_parametersPoly,
        trControl = ctrl_cv5)


model_SVM_poly

```

###Support vector machine - radial


Here we also have to tune parameters, by trial and error I know that parameter C must be around 26:

```{r}
parametersC_sigma <- 
  expand.grid(C = c(24, 25, 26, 27, 28),
              sigma = c(0.05, 0.1, 0.2, 0.5, 1))



model_SVM_radial <- train(TravelInsurance ~ ., 
        data = insurance_train %>% 
          dplyr::select(-X, - GraduateOrNot, -ChronicDiseases, -Employment.Type), 
          method = "svmRadial",
          tuneGrid = parametersC_sigma,
          trControl = ctrl_cv5)



model_SVM_radial

```
### Models evaluation 

To evaluate the models and compare the results on the test sample, I will use confusionMatrix function to obtain basic evaluation measures:

```{r}
model_logistic_forecasts <- predict(model_logistic2,
                                  insurance_test,
                                  type = "prob")



confusionMatrix(data = as.factor(ifelse(model_logistic_forecasts["Yes"] > 0.5,
                                        "Yes",
                                        "No")),
                  reference = insurance_test$TravelInsurance,
                positive = "Yes")






model_knn_forecasts <- predict(model_knn,
                                  insurance_test,
                                  type = "prob")





confusionMatrix(data = as.factor(ifelse(model_knn_forecasts["Yes"] > 0.5,
                                        "Yes",
                                        "No")),
                  reference = insurance_test$TravelInsurance,
                positive = "Yes")




model_SVM_poly_forecasts <- predict(model_SVM_poly,
                                  insurance_test)



confusionMatrix(data = model_SVM_poly_forecasts,
                reference = insurance_test$TravelInsurance,
                positive = "Yes")

model_SVM_radial_forecasts <- predict(model_SVM_radial,
                                  insurance_test)




confusionMatrix(data = model_SVM_radial_forecasts,
                reference = insurance_test$TravelInsurance,
                positive = "Yes")

```


###Summary


The best model from the four presented above seem to be SVM models (radial kernel function slightly better than polynomial) - this model gives highest  balanced accuracy, sensitivity and specificity measures. The logistic regression model is the one that differs in terms of performance measures the most, which is why it should be rejested.

For all 4 presented models we may see that sensitivity was estimated at around 53% and specificity much higher - around 95%. This is due to the fact that the dataset is not balanced - there representation of customers who didn't buy additional insurance is around 45% higher.


###Refrences

1)Lab materials - R scripts and presentations

2)https://www.kaggle.com/tejashvi14/travel-insurance-prediction-data

3)https://www.rdocumentation.org/

4)https://stackoverflow.com/


